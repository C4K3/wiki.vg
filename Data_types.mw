All data sent over the network is [http://en.wikipedia.org/wiki/Endianness#Big-endian big-endian], that is the bytes are sent from most significant byte to least significant byte. The majority of everyday computers are little-endian, therefore it may be necessary to change the endianness before sending data over the network.

Other than 'String' and 'Metadata', which are decoded with a custom function, these data formats are identical to those provided by the Java classes [http://download.oracle.com/javase/1.4.2/docs/api/java/io/DataInputStream.html DataInputStream] and [http://download.oracle.com/javase/1.4.2/docs/api/java/io/DataOutputStream.html DataOutputStream].

{| class="wikitable"
|- class="row0"
| class="col0" |
! class="col1" | Size
! class="col2" | Range
! class="col3" | Notes
|- class="row1"
! class="col0 centeralign" | bool
| class="col1 centeralign" | 1
| class="col2" | 0 or 1
| class="col3" | Value can be either true (0x01) or false (0x00)
|- class="row2"
! class="col0 centeralign" | byte
| class="col1 centeralign" | 1
| class="col2" | -128 to 127
| class="col3" | Signed, two's complement
|- class="row3"
! class="col0 centeralign" | short
| class="col1 centeralign" | 2
| class="col2" | -32768 to 32767
| class="col3" | Signed, two's complement
|- class="row4"
! class="col0 centeralign" | int
| class="col1 centeralign" | 4
| class="col2" | -2147483648 to 2147483647
| class="col3" | Signed, two's complement
|- class="row5"
! class="col0 centeralign" | long
| class="col1 centeralign" | 8
| class="col2" | -9223372036854775808 to 9223372036854775807
| class="col3" | Signed, two's complement
|- class="row6"
! class="col0 centeralign" | float
| class="col1 centeralign" | 4
| class="col2" |
See [http://java.sun.com/docs/books/jls/third_edition/html/typesValues.html#4.2.3 this]
| class="col3" | Single-precision 32-bit IEEE 754 floating point
|- class="row7"
! class="col0 centeralign" | double
| class="col1 centeralign" | 8
| class="col2" |
See [http://java.sun.com/docs/books/jls/third_edition/html/typesValues.html#4.2.3 this]
| class="col3" | Double-precision 64-bit IEEE 754 floating point
|- class="row8"
! class="col0 centeralign" | string
| class="col1 centeralign" | ≥ 2 <br />≤ 240
| class="col2" | N/A
| class="col3" | [http://en.wikipedia.org/wiki/UTF-16 UTF-16] big-endian string prefixed by a short containing the length of the string in code units.

UTF-16 is a variable-length encoding, which means that a single Unicode code point (what most programmers think of as a "character") may be encoded by a variable number of code units.

UTF-16 encodes code points as either one or two 16 bit code units.

Characters in the Basic Multilingual Plane (U+0000 through U+FFFF inclusive) are encoded as one 16 bit code unit.

Characters in the other Unicode planes (U+10000 through U+10FFFF inclusive) are encoded as two 16 bit code units (a high/low "surrogate pair").

Therefore, the length in bytes of a string may be obtained by multiplying the number of code units by two, and the opposite operation may be performed by dividing by two.

However, since UTF-16 is variable-length, the number of code units is totally unrelated to the number of code points (i.e. "characters"), and you will actually have to decode the string to obtain this information.

It was historically believed that the Minecraft protocol used the fixed-width encoding UCS-2, however this has since been proven to be incorrect.
|- class="row9"
! class="col0 centeralign" | metadata
| class="col1 centeralign" | Varies
| class="col2" | See [[Entities#Entity_Metadata_Format|this]]
| class="Col3" | 
|}

Some data may be stored as an "absolute integer", which is a more precise kind of integer, and a less precise kind of double.  The conversion from double to absolute integer is like so:

abs_int = (int)double * 32;

And back again:

double = (double)abs_int / 32;

[[Category:Protocol Details]]
[[Category:Minecraft Modern]]
